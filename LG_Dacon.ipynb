{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import datetime as dt\n",
    "\n",
    "from sklearn.metrics import roc_auc_score  \n",
    "from sklearn.model_selection import KFold,StratifiedKFold,RepeatedStratifiedKFold      \n",
    "from bayes_opt import BayesianOptimization    \n",
    "from functools import partial               \n",
    "import lightgbm as lgb                      \n",
    "import warnings\n",
    "from catboost import CatBoostClassifier\n",
    "warnings.filterwarnings(\"ignore\") \n",
    "\n",
    "pd.set_option('display.max_columns', 1500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# datetime 함수\n",
    "\n",
    "def make_datetime(x):\n",
    "    # string 타입의 Time column을 datetime 타입으로 변경\n",
    "    x     = str(x)\n",
    "    year  = int(x[:4])\n",
    "    month = int(x[4:6])\n",
    "    day   = int(x[6:8])\n",
    "    hour  = int(x[8:10])\n",
    "    #mim  = int(x[10:12])\n",
    "    #sec  = int(x[12:])\n",
    "    return dt.datetime(year, month, day, hour)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data load\n",
    "\n",
    "train_qual = pd.read_csv('./data/train_quality_data.csv')\n",
    "train_err = pd.read_csv('./data/train_err_data.csv')\n",
    "train_problem = pd.read_csv('./data/train_problem_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_data load\n",
    "\n",
    "test_err = pd.read_csv('./data/test_err_data.csv')\n",
    "test_qual = pd.read_csv('./data/test_quality_data.csv')\n",
    "test_submission = pd.read_csv('./data/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# datetime 변환 후 주말 1, 평일 0 으로 저장\n",
    "\n",
    "train_err['datetime'] = train_err['time'].apply(make_datetime)\n",
    "test_err['datetime'] = test_err['time'].apply(make_datetime)\n",
    "\n",
    "train_err['dayname'] = pd.to_datetime(train_err['datetime'], format='%Y%m%d').map(lambda x : x.strftime('%A'))\n",
    "d1 = {'Monday':0, 'Tuesday':0, 'Wednesday':0, 'Thursday':0,\n",
    "      'Friday':0, 'Saturday':1, 'Sunday':1}\n",
    "train_err['we_or_wk'] = train_err['dayname'].map(d1)\n",
    "\n",
    "test_err['dayname'] = pd.to_datetime(test_err['datetime'], format='%Y%m%d').map(lambda x : x.strftime('%A'))\n",
    "d1 = {'Monday':0, 'Tuesday':0, 'Wednesday':0, 'Thursday':0,\n",
    "      'Friday':0, 'Saturday':1, 'Sunday':1}\n",
    "test_err['we_or_wk'] = test_err['dayname'].map(d1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 11월 동안의 데이터만 사용 (train, test에서 모두 10월, 12월 데이터는 거의 없어서 11월만 사용)\n",
    "\n",
    "train_err = train_err.loc[(train_err.datetime >= pd.to_datetime('2020-11-01 00:00:00')) & (train_err.datetime <= pd.to_datetime('2020-11-30 23:59:59'))]\n",
    "test_err = test_err.loc[(test_err.datetime >= pd.to_datetime('2020-11-01 00:00:00')) & (test_err.datetime <= pd.to_datetime('2020-11-30 23:59:59'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train, test error 데이터에 주, 일, 시간 데이터 분리\n",
    "\n",
    "train_err['week'] = train_err.datetime.dt.isocalendar().week\n",
    "test_err['week'] = test_err.datetime.dt.isocalendar().week\n",
    "\n",
    "train_err['day'] = train_err.datetime.dt.day\n",
    "test_err['day'] = test_err.datetime.dt.day\n",
    "\n",
    "train_err['hour'] = train_err.datetime.dt.hour\n",
    "test_err['hour'] = test_err.datetime.dt.hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 파생변수 생성\n",
    "+ 유저별 최신 펌웨어 버전 (fwver_most_recent)\n",
    "+ 유저별 시간대별 (시간대를 4 섹션으로 구분) error 발생 횟수 카운트 (time_count)\n",
    "+ 유저별 가장 오래 사용한 펌웨어 버전 (longest_used_fwver)\n",
    "+ 유저별 펌웨어 버전 변화하는 것 잡아내는 것 (fwver_change)\n",
    "+ 유저별 가장 많이 사용한 펌웨어 버전 (most_used_fwver)\n",
    "+ train_problem에 있는 펌웨어 버전에 해당하는지 (problem_fwver_check)\n",
    "+ train_problem에 있는 펌웨어 버전에 몇 번 해당하는지 (problem_fwver_check_count)\n",
    "+ 유저별 connection error 카운트 (connection_user_count)\n",
    "+ err 데이터에서 유저별 요일별 error 발생 횟수 카운트 (day_count)\n",
    "+ 유저별 펌웨어 버전 변경 횟수 카운트 (fw_changed_count)\n",
    "+ 요일별 errtype의 평균, 표준편차, 최댓값 (day_errtype)\n",
    "+ 유저 - 모델명 사용 여부만 (user_model_count1)\n",
    "+ 유저 - 모델명 err에 찍힌 개수만큼 (user_model_count2)\n",
    "+ 유저 - 모델명 err에 찍힌 개수만큼 (연월일 기준 중복 제거) (user_model_count3)\n",
    "+ 주말/주중, 주별, 일별, 시간별 에러코드의 평균, 표준편차, 최댓값"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ model_nm별 카운트\n",
    "+ err_type별 카운트\n",
    "+ err_code 상위 50개 카운트\n",
    "+ quality issue 유무\n",
    "+ connect 관련 error 발생 카운트\n",
    "+ 전체 err_type 합계"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## fwver_most_recent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fwver_most_recent(data)\n",
    "    data.sort_values(by = ['user_id', 'time'], inplace = True)\n",
    "    data2 = data[['user_id', 'time', 'fwver']]\n",
    "    data2.drop_duplicates('user_id', keep = 'last', inplace = True)\n",
    "    data2['fwver'] = data2['fwver'].apply(lambda x: x[:5])\n",
    "    data2['fwver'] = data2['fwver'].apply(lambda x: x if x != '8.5.3' else '8.5')\n",
    "    fwver_most_recent = data2[['user_id', 'fwver']].reset_index(drop = True)\n",
    "    fwver_most_recent['fwver'] = fwver_most_recent['fwver'].str.lstrip('0')\n",
    "\n",
    "return fwver_most_recent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## time_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_count1(x):\n",
    "    if x >= '06' and x <= '11':\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def time_count2(x):\n",
    "    if x >= '12' and x <= '17':\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "def time_count3(x):\n",
    "    if x >= '18' and x <= '23':\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def time_count4(x):\n",
    "    if x >= '00' and x <= '05':\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_count(data):\n",
    "    data['time'] = data['time'].apply(lambda x: str(x)[8:10])\n",
    "    \n",
    "    data['time_06_11'] = data['time'].apply(time_count1)\n",
    "    data['time_12_17'] = data['time'].apply(time_count2)\n",
    "    data['time_18_23'] = data['time'].apply(time_count3)\n",
    "    data['time_00_05'] = data['time'].apply(time_count4)\n",
    "    \n",
    "    time_count = data.groupby('user_id')['time_06_11', 'time_12_17', 'time_18_23', 'time_00_05'].sum()\n",
    "    time_count = time_count.reset_index()\n",
    "    \n",
    "    return time_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## longest_used_fwver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_datetime2(x):\n",
    "    # string 타입의 Time column을 datetime 타입으로 변경\n",
    "    x     = str(x)\n",
    "    year  = int(x[:4])\n",
    "    month = int(x[4:6])\n",
    "    day   = int(x[6:8])\n",
    "    \n",
    "    return dt.datetime(year, month, day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def most_used_fwver(data):\n",
    "    data['datetime2'] = data['time'].apply(make_datetime2)\n",
    "    data = pd.DataFrame(data.groupby(['user_id', 'datetime2'])['fwver'].value_counts())\n",
    "    data.columns = ['fwver_count']\n",
    "    data.reset_index(inplace = True)\n",
    "    data = pd.DataFrame(data.groupby(['user_id', 'fwver'])['fwver_count'].sum())\n",
    "    data = data.sort_values(by = 'fwver_count', ascending = False)\n",
    "    data.reset_index(inplace = True)\n",
    "    data = data.drop_duplicates('user_id', keep = 'first')\n",
    "    data = data.sort_values('user_id', ascending = True)\n",
    "    data['count'] = 1\n",
    "    data = pd.pivot_table(data, index = 'user_id', columns = 'fwver', values = 'count', fill_value = 0).reset_index()\n",
    "    data_col = ['fwv_' + str(i) for i in data.columns[1:]]\n",
    "    data_col.insert(0, 'user_id')\n",
    "    data.columns = data_col\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## fwver_change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fwver 변화하는 것 잡아내는 함수\n",
    "\n",
    "def get_fwver_change(data):\n",
    "    data['datetime2'] = data['time'].apply(make_datetime2)\n",
    "    data = pd.DataFrame(data.groupby(['user_id', 'datetime2'])['fwver'].value_counts())\n",
    "    data.columns = ['fwver_count']\n",
    "    data.reset_index(inplace = True)\n",
    "    data = pd.DataFrame(data.groupby(['user_id', 'fwver'])['fwver_count'].sum())\n",
    "    data = data.reset_index()\n",
    "    \n",
    "    users = data['user_id'].unique()\n",
    "    tmp = []\n",
    "    \n",
    "    for user in users:\n",
    "        tmp.append(tuple(data[data['user_id'] == user]['fwver'].unique()))\n",
    "        \n",
    "    fw = list(set(tmp))\n",
    "    return fw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_fw = get_fwver_change(train_err)\n",
    "te_fw = get_fwver_change(test_err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train, test의 fwver 변화한 것 모두 합침\n",
    "\n",
    "fw_change_list = list(set(tr_fw + te_fw))\n",
    "fw_change_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fwver 변화 잡는거 이어서 데이터프레임 만들기\n",
    "\n",
    "def make_fwver_change(data, train=True):\n",
    "    data['datetime2'] = data['time'].apply(make_datetime2)\n",
    "    data = pd.DataFrame(data.groupby(['user_id', 'datetime2'])['fwver'].value_counts())\n",
    "    data.columns = ['fwver_count']\n",
    "    data.reset_index(inplace = True)\n",
    "    data = pd.DataFrame(data.groupby(['user_id', 'fwver'])['fwver_count'].sum())\n",
    "    data = data.reset_index()\n",
    "    \n",
    "    users = data['user_id'].unique()\n",
    "    \n",
    "    fwver_change = pd.DataFrame()\n",
    "    if train == True:\n",
    "        fwver_change['user_id'] = range(10000, 25000)\n",
    "    else:\n",
    "        fwver_change['user_id'] = range(30000, 44999)\n",
    "    \n",
    "    for col in fw_change_list:\n",
    "        column = '_'.join(col)\n",
    "        fwver_change[column] = 0\n",
    "        \n",
    "    for user in users:\n",
    "        col_name = tuple(data[data['user_id'] == user]['fwver'].unique())\n",
    "        col_name = '_'.join(col_name)\n",
    "        fwver_change.loc[fwver_change['user_id'] == user, col_name] = 1\n",
    "    \n",
    "    return fwver_change"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## most_used_fwver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def most_used_fwver(data, train = True):\n",
    "    data['datetime2'] = data['time'].apply(make_datetime2)\n",
    "    data = pd.DataFrame(data.groupby(['user_id', 'datetime2'])['fwver'].value_counts())\n",
    "    data.columns = ['fwver_count']\n",
    "    data.reset_index(inplace = True)\n",
    "    data = pd.DataFrame(data.groupby(['user_id', 'fwver'])['fwver_count'].sum())\n",
    "    data = data.sort_values(by = 'fwver_count', ascending = False)\n",
    "    data.reset_index(inplace = True)\n",
    "    data = data.drop_duplicates('user_id', keep = 'first')\n",
    "    data = data.sort_values('user_id', ascending = True)\n",
    "    data['count'] = 1\n",
    "    users = data['user_id'].unique()\n",
    "    most_used = pd.DataFrame()\n",
    "    if train == True:\n",
    "        most_used['user_id'] = range(10000, 25000)\n",
    "    else:\n",
    "        most_used['user_id'] = range(30000, 44999)\n",
    "    \n",
    "    for col in fw_list:\n",
    "        column = 'fwv_' + col\n",
    "        most_used[column] = 0\n",
    "    \n",
    "    for user in users:\n",
    "        col_name = data[data['user_id'] == user]['fwver']\n",
    "        col_name = 'fwv_' + col_name\n",
    "        most_used.loc[most_used['user_id'] == user, col_name] = 1\n",
    "    \n",
    "    return most_used    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## problem_fwver_check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def problem_fwver_check(data, train = True):\n",
    "    \n",
    "    users = data['user_id'].unique()\n",
    "    \n",
    "    problem_fwver_check = pd.DataFrame()\n",
    "    \n",
    "    if train == True:\n",
    "        problem_fwver_check['user_id'] = range(10000, 25000)\n",
    "    else:\n",
    "        problem_fwver_check['user_id'] = range(30000, 44999)\n",
    "    \n",
    "    for col in train_problem_fw_list:\n",
    "        problem_fwver_check[col] = 0\n",
    "    \n",
    "    for user in users:\n",
    "        for col in train_problem_fw_list:\n",
    "            if col in data[data['user_id'] == user]['fwver'].tolist():\n",
    "                problem_fwver_check.loc[problem_fwver_check['user_id'] == user, col] = 1\n",
    "    \n",
    "    return problem_fwver_check"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## problem_fwver_check_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def problem_fwver_check_count(data):\n",
    "    data = problem_fwver_check_count(data)\n",
    "    data['problem_fw_count'] = data[data.columns[1:]].sum(axis = 1)\n",
    "    data2 = data[['user_id', 'problem_fw_count']]\n",
    "    \n",
    "    return data2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## connection_err_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def connection_err_count(data):\n",
    "    data = data[['user_id', 'time', 'errcode']]\n",
    "    data['count'] = 1\n",
    "    data2 = data[(data['errcode'] == 'connection timeout') | (data['errcode'] == 'connection fail to establish') | \n",
    "                 (data['errcode'] == 'connectionterminated by local host') | (data['errcode'] == 'connection fail for LMP response timout') | \n",
    "                 (data['errcode'] == 'L2CAP connection cancelled')]\n",
    "    data3 = pd.pivot_table(data2, index = 'user_id', columns = 'errcode', values = 'count', aggfunc = 'sum', fill_value = 0).reset_index()\n",
    "    data4 = data[['user_id']].drop_duplicates().reset_index(drop = True)\n",
    "    data5 = pd.merge(data4, data3, how = 'left')\n",
    "    data5 = data5.fillna(0)\n",
    "    return data5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## day_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def user_dayname_count(data):\n",
    "    data = pd.DataFrame(data.groupby('user_id')['dayname'].value_counts())\n",
    "    data.columns = ['day_count']\n",
    "    data.reset_index(inplace = True)\n",
    "    data = pd.pivot_table(data, values = 'day_count', index = 'user_id', columns = 'dayname', fill_value = 0).reset_index()\n",
    "    data = data[['user_id', 'Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']]\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## day_errtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def day_errtype(data, num_of_users, first_index):\n",
    "\n",
    "    data['day'] = data.datetime.dt.isocalendar().day\n",
    "\n",
    "    df3 = data[['user_id', 'errtype', 'day']]\n",
    "\n",
    "    df4 = df3[['user_id', 'day', 'errtype']].value_counts().to_frame().reset_index()\n",
    "\n",
    "    df5 = df4.sort_values(['user_id', 'day']).rename(columns = {0 : 'counts'}).reset_index(drop = True)\n",
    "\n",
    "    tmp1 = df5.loc[df5['day'] == 1][['user_id', 'errtype', 'counts']].values\n",
    "    tmp2 = df5.loc[df5['day'] == 2][['user_id', 'errtype', 'counts']].values\n",
    "    tmp3 = df5.loc[df5['day'] == 3][['user_id', 'errtype', 'counts']].values\n",
    "    tmp4 = df5.loc[df5['day'] == 4][['user_id', 'errtype', 'counts']].values\n",
    "    tmp5 = df5.loc[df5['day'] == 5][['user_id', 'errtype', 'counts']].values\n",
    "    tmp6 = df5.loc[df5['day'] == 6][['user_id', 'errtype', 'counts']].values\n",
    "    tmp7 = df5.loc[df5['day'] == 7][['user_id', 'errtype', 'counts']].values\n",
    "    \n",
    "    day_data = np.zeros((num_of_users, 42, 7))\n",
    "\n",
    "    for i, dfa in enumerate([tmp1, tmp2, tmp3, tmp4, tmp5, tmp6, tmp7]):\n",
    "        for inx, val1, val2 in tqdm(dfa):\n",
    "            day_data[:, :, i][inx - first_index, val1 - 1] = val2\n",
    "\n",
    "    day_data_mean = day_data.mean(axis = 2)\n",
    "    day_data_std = day_data.std(axis = 2)\n",
    "    day_data_max = day_data.max(axis = 2)\n",
    "\n",
    "    ddmean = pd.DataFrame(day_data_mean, columns = ['err_type_day_mean' + str(i) for i in range(1, 43)])\n",
    "    ddstd = pd.DataFrame(day_data_std, columns = ['err_type_day_std' + str(i) for i in range(1, 43)])\n",
    "    ddmax = pd.DataFrame(day_data_max, columns = ['err_type_day_max' + str(i) for i in range(1, 43)])\n",
    "    \n",
    "    ddmean.drop('err_type_day_mean29', axis = 1, inplace = True)\n",
    "    ddstd.drop('err_type_day_std29', axis = 1, inplace = True)\n",
    "    ddmax.drop('err_type_day_max29', axis = 1, inplace = True)\n",
    "    \n",
    "    return ddmean, ddstd, ddmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_errtype_day_mean, train_errtype_day_std, train_errtype_day_max = day_errtype(train_err, 15000, 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_errtype_day_mean, test_errtype_day_std, test_errtype_day_max = day_errtype(test_err, 14999, 30000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## user_model_count1 (유저 - 모델명 사용 여부만)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def user_model_count1(data):\n",
    "    data = data[['user_id', 'time', 'model_nm']]\n",
    "    data['count'] = 1\n",
    "    data = pd.pivot_table(data, index = 'user_id', columns = 'model_nm', values = 'count', fill_value = 0).reset_index()\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## user_model_count2 (유저 - 모델명 err에 찍힌 개수만큼)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def user_model_count2(data):\n",
    "    data = data[['user_id', 'time', 'model_nm']]\n",
    "    data['count'] = 1\n",
    "    data['time'] = data['time'].apply(lambda x: str(x)[:8])\n",
    "    data = pd.DataFrame(data.groupby('user_id')['model_nm'].value_counts())\n",
    "    data.columns = ['model_count']\n",
    "    data.reset_index(inplace = True)\n",
    "    data = pd.pivot_table(data, index = 'user_id', columns = 'model_nm', values = 'model_count', fill_value = 0).reset_index()\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## user_model_count3 (유저 - 모델명 err에 찍힌 개수만큼 (연월일 기준 중복 제거))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def user_model_count3(data):\n",
    "    data = data[['user_id', 'time', 'model_nm']]\n",
    "    data['count'] = 1\n",
    "    data['time'] = data['time'].apply(lambda x: str(x)[:8])\n",
    "    data = data.drop_duplicates(['user_id', 'time', 'model_nm'], keep = 'last')\n",
    "    data = pd.DataFrame(data.groupby('user_id')['model_nm'].value_counts())\n",
    "    data.columns = ['model_count']\n",
    "    data.reset_index(inplace = True)\n",
    "    data = pd.pivot_table(data, index = 'user_id', columns = 'model_nm', values = 'model_count', fill_value = 0).reset_index()\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 주말/주중, 주별, 일별, 시간별 에러코드의 평균, 표준편차, 최댓값"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def we_or_wk(df,num_df_user,first_index):\n",
    "    \n",
    "    df = df.loc[(df.datetime >= pd.to_datetime('2020-11-01 00:00:00')) & (df.datetime <= pd.to_datetime('2020-11-30 23:59:59'))]\n",
    "    datas = df[['user_id','errtype','we_or_wk']]\n",
    "    df_ = datas[['user_id','we_or_wk','errtype']].value_counts().to_frame().reset_index()\n",
    "    df_ = df_.sort_values(['user_id','we_or_wk']).rename(columns = {0:'counts'}).reset_index(drop = True)\n",
    "\n",
    "    df1 = df_.loc[df_.we_or_wk == 0][['user_id','errtype','counts']].values\n",
    "    df2 = df_.loc[df_.we_or_wk == 1][['user_id','errtype','counts']].values\n",
    "\n",
    "    day_data = np.zeros((num_df_user,42,2))\n",
    "    for i, dfa in enumerate([df1,df2]):\n",
    "        for inx, val1,val2 in dfa:\n",
    "            day_data[:, :, i][inx-first_index,val1 - 1] = val2\n",
    "\n",
    "    m = day_data.mean(axis = 2)\n",
    "    std = day_data.std(axis = 2)\n",
    "    m_2 = day_data.max(axis = 2)\n",
    "\n",
    "    m = pd.DataFrame(m, columns = ['err_type_weorwk_mean' + str(i) for i in range(1, 43)])\n",
    "    std = pd.DataFrame(std, columns = ['err_type_weorwk_std' + str(i) for i in range(1, 43)])\n",
    "    m_2 = pd.DataFrame(m_2, columns = ['err_type_weorwk_max' + str(i) for i in range(1, 43)])\n",
    "\n",
    "    m.drop('err_type_weorwk_mean29', axis = 1, inplace = True)\n",
    "    std.drop('err_type_weorwk_std29', axis = 1, inplace = True)\n",
    "    m_2.drop('err_type_weorwk_max29', axis = 1, inplace = True)\n",
    "    return m, std, m_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wk(df,num_df_user,first_index):\n",
    "\n",
    "    df = df.loc[(df.datetime >= pd.to_datetime('2020-11-01 00:00:00')) & (df.datetime <= pd.to_datetime('2020-11-30 23:59:59'))]\n",
    "    datas = df[['user_id','errtype','week']]\n",
    "    df_ = datas[['user_id','week','errtype']].value_counts().to_frame().reset_index()\n",
    "    df_ = df_.sort_values(['user_id','week']).rename(columns = {0:'counts'}).reset_index(drop = True)\n",
    "\n",
    "    df1 = df_.loc[df_.week == 44][['user_id','errtype','counts']].values\n",
    "    df2 = df_.loc[df_.week == 45][['user_id','errtype','counts']].values\n",
    "    df3 = df_.loc[df_.week == 46][['user_id','errtype','counts']].values\n",
    "    df4 = df_.loc[df_.week == 47][['user_id','errtype','counts']].values\n",
    "    df5 = df_.loc[df_.week == 48][['user_id','errtype','counts']].values\n",
    "\n",
    "    day_data = np.zeros((num_df_user, 42, 5))\n",
    "    for i, dfa in enumerate([df1, df2, df3, df4, df5]):\n",
    "        for inx, val1, val2 in dfa:\n",
    "            day_data[:, :, i][inx-first_index,val1 - 1] = val2\n",
    "\n",
    "    m = day_data.mean(axis = 2)\n",
    "    std = day_data.std(axis = 2)\n",
    "    m_2 = day_data.max(axis = 2)\n",
    "    \n",
    "    m = pd.DataFrame(m, columns = ['err_type_wk_mean' + str(i) for i in range(1, 43)])\n",
    "    std = pd.DataFrame(std, columns = ['err_type_wk_std' + str(i) for i in range(1, 43)])\n",
    "    m_2 = pd.DataFrame(m_2, columns = ['err_type_wk_max' + str(i) for i in range(1, 43)])\n",
    "\n",
    "    m.drop('err_type_wk_mean29', axis = 1, inplace = True)\n",
    "    std.drop('err_type_wk_std29', axis = 1, inplace = True)\n",
    "    m_2.drop('err_type_wk_max29', axis = 1, inplace = True)\n",
    "    \n",
    "    return m, std, m_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dy(df,num_df_user,first_index): \n",
    "    \n",
    "    df = df.loc[(df.datetime >=pd.to_datetime('2020-11-01 00:00:00'))& (df.datetime<=pd.to_datetime('2020-11-30 23:59:59'))]\n",
    "    datas = df[['user_id','errtype','day']]\n",
    "    df_=datas[['user_id','day','errtype']].value_counts().to_frame().reset_index()\n",
    "    df_ =df_.sort_values(['user_id','day']).rename(columns = {0:'counts'}).reset_index(drop=True)\n",
    "\n",
    "\n",
    "    day_data = np.zeros((num_df_user,42,30))\n",
    "    for i in range(30):\n",
    "        dfa = df_.loc[df_['day']==(i+1)][['user_id','errtype','counts']].values\n",
    "        for inx , val1 ,val2 in dfa:\n",
    "            day_data[:,:,i][inx-first_index,val1-1] = val2\n",
    "\n",
    "    m=day_data.mean(axis=2)\n",
    "    std=day_data.std(axis=2)       \n",
    "    m_2=day_data.max(axis=2)\n",
    "    \n",
    "    m=pd.DataFrame(m,columns=['err_type_dy_mean'+str(i) for i in range(1,43)])\n",
    "    std=pd.DataFrame(std,columns=['err_type_dy_std'+str(i) for i in range(1,43)])\n",
    "    m_2=pd.DataFrame(m_2,columns=['err_type_dy_max'+str(i) for i in range(1,43)])\n",
    "\n",
    "    m.drop('err_type_dy_mean29',axis=1,inplace=True)\n",
    "    std.drop('err_type_dy_std29',axis=1,inplace=True)\n",
    "    m_2.drop('err_type_dy_max29',axis=1,inplace=True)\n",
    "    \n",
    "    return m,std,m_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hr(df,num_df_user,first_index):     \n",
    "    \n",
    "    df = df.loc[(df.datetime >=pd.to_datetime('2020-11-01 00:00:00'))& (df.datetime<=pd.to_datetime('2020-11-30 23:59:59'))]\n",
    "    datas = df[['user_id','errtype','hour']]\n",
    "    df_=datas[['user_id','hour','errtype']].value_counts().to_frame().reset_index()\n",
    "    df_ =df_.sort_values(['user_id','hour']).rename(columns = {0:'counts'}).reset_index(drop=True)\n",
    "\n",
    "\n",
    "    day_data = np.zeros((num_df_user,42,24))\n",
    "    for i in range(24):\n",
    "        dfa = df_.loc[df_['hour']==i][['user_id','errtype','counts']].values\n",
    "        for inx , val1 ,val2 in dfa:\n",
    "            day_data[:,:,i][inx-first_index,val1-1] = val2\n",
    "\n",
    "    m=day_data.mean(axis=2)\n",
    "    std=day_data.std(axis=2)       \n",
    "    m_2=day_data.max(axis=2)\n",
    "    \n",
    "    m=pd.DataFrame(m,columns=['err_type_hr_mean'+str(i) for i in range(1,43)])\n",
    "    std=pd.DataFrame(std,columns=['err_type_hr_std'+str(i) for i in range(1,43)])\n",
    "    m_2=pd.DataFrame(m_2,columns=['err_type_hr_max'+str(i) for i in range(1,43)])\n",
    "\n",
    "    m.drop('err_type_hr_mean29',axis=1,inplace=True)\n",
    "    std.drop('err_type_hr_std29',axis=1,inplace=True)\n",
    "    m_2.drop('err_type_hr_max29',axis=1,inplace=True)\n",
    "    \n",
    "    return m,std,m_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# errcode 중복 정리\n",
    "\n",
    "train_err['errcode'] = train_err['errcode'].apply(lambda x: str(x).strip())\n",
    "test_err['errcode'] = test_err['errcode'].apply(lambda x: str(x).strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_int(row):\n",
    "    if ',' in str(row):\n",
    "        string = str(row).replace(',', '')\n",
    "    elif '.' in str(row):\n",
    "        string = str(row).replace('.', '')\n",
    "    else:\n",
    "        string = str(row)\n",
    "    return int(string)\n",
    "\n",
    "def make_col_prefix(dataframe):\n",
    "    new_c = dataframe.columns\n",
    "    new_cols = []\n",
    "    for i in new_c:\n",
    "        if str(i).isdigit() == True:\n",
    "            newname = 'errtype_'+str(i)\n",
    "            new_cols.append(newname)\n",
    "        else:\n",
    "            new_cols.append(i)\n",
    "    return new_cols\n",
    "\n",
    "def make_dataframe(err, qual, train=True):\n",
    "    if train == True:\n",
    "        err_users = err['user_id'].unique() # error data에 있는 unique 유저들\n",
    "        df = pd.DataFrame() # 빈 데이터프레임 생성\n",
    "        df['user_id'] = err_users # user 생성\n",
    "    else:\n",
    "        df = test_submission[['user_id']]\n",
    "    \n",
    "    err['count'] = 1 # count 세기 위한 용도로 컬럼 추가\n",
    "    \n",
    "    \n",
    "    # 1) model_nm : model_nm를 pivot_table로 만듬\n",
    "    print('making model_nm data...')\n",
    "    err_model_nm = pd.pivot_table(err, index='user_id', columns='model_nm', values='count', fill_value=0)\n",
    "    err_model_nm = err_model_nm.reset_index()\n",
    "    print('done.')\n",
    "    \n",
    "    # 2) errtype : errtype을 pivot_table로 만듬\n",
    "    print('making errtype data...')\n",
    "    err_type = pd.pivot_table(err, index='user_id', columns='errtype', values='count', aggfunc='sum', fill_value=0)\n",
    "    err_type = err_type.reset_index()\n",
    "    err_type_cols = make_col_prefix(err_type)\n",
    "    err_type.columns = err_type_cols\n",
    "    print('done.')\n",
    "    \n",
    "    # 3) errcode : errcode 상위 50개를 pivot_table로 만듬.\n",
    "    print('making errcode data...')\n",
    "    errcode_50 = train_err['errcode'].value_counts(ascending=False)[:50].index # train_err에서 나온 상위 50개 errcode\n",
    "    err_code = err[err['errcode'].isin(errcode_50)] # errcode_50에 해당하는 errcode만 뽑음.\n",
    "    err_code = pd.pivot_table(err_code, index=['user_id'], columns='errcode', values='count', fill_value=0, aggfunc='sum').reset_index()\n",
    "    print('done.')\n",
    "    \n",
    "    # 4) quality_issue : qual에 있는 사용자만을 뽑아서 만듬.\n",
    "    print('making quality_issue data...')\n",
    "    qual_id = qual.user_id.unique()\n",
    "    print('done.')\n",
    "    \n",
    "    \n",
    "    # 5) quality_0 ~ quality_12 : qual 에서 먼저 nan값 0처리해주고, 쉼표/점 처리하여 str -> int 화해야함.\n",
    "    print('making quality_log data...')\n",
    "    qual.fillna(0, inplace=True)\n",
    "    for i in range(13):\n",
    "        qual[f'quality_{i}'] = qual[f'quality_{i}'].apply(make_int)\n",
    "    \n",
    "#     model_fw = err[['model_nm', 'fwver']].drop_duplicates().reset_index(drop=True) # model_nm와 fwver의 중복값 모두 제거한 것.\n",
    "#     qual = pd.merge(qual, model_fw, on=['fwver']) \n",
    "    qual = qual.groupby(['user_id']).sum().reset_index()\n",
    "    qual = qual.drop(columns='time')\n",
    "#     new_qual_avg = qual.groupby(['user_id']).agg(lambda x: sum(x)/len(x)).reset_index()\n",
    "#     new_qual_avg = new_qual_avg.drop(columns='time')\n",
    "#     new_qual_avg\n",
    "    print('done.')\n",
    "    \n",
    "    # 6) weekend: 주말 =1, 주중 0\n",
    "    print('making weekend data...')\n",
    "    wk=pd.pivot_table(err, index=['user_id'], columns=['we_or_wk'], values='count', aggfunc='sum', fill_value=0).reset_index()\n",
    "    wk_col=['weekend_'+str(i) for i in wk.columns[1:]]\n",
    "    wk_col.insert(0,'user_id')\n",
    "    wk.columns=wk_col\n",
    "    print('done.')\n",
    "    \n",
    "    # df에 column 추가 : model_nm, errtype, errcode, quality_issue, quality_0~12, weekend, time 순으로\n",
    "    print('Merging data into DataFrame...')\n",
    "    df = pd.merge(df, err_model_nm, on=['user_id'], how='left')\n",
    "    df = pd.merge(df, err_type, on=['user_id'], how='left')\n",
    "    df = pd.merge(df, err_code, on=['user_id'], how='left')\n",
    "    df['quality_issue'] = 0\n",
    "    df.loc[df['user_id'].isin(qual_id), 'quality_issue'] = 1\n",
    "    df = pd.merge(df, qual, on=['user_id'], how='left')\n",
    "    df = pd.merge(df, wk, on=['user_id'], how='left')\n",
    "    \n",
    "    #전체 건수 합계 추가 \n",
    "    df['total_err']=df.loc[:,['errtype_'+str(i) for i in range(1,29)]+['errtype_'+str(i) for i in range(30,43)]].sum(axis=1)\n",
    "    \n",
    "    \n",
    "    # 새로 만든 파생변수들을 모두 merge 하면 됨\n",
    "    if train == True:\n",
    "        df = pd.merge(df, time_tr, on=['user_id'], how='left')\n",
    "        df = pd.merge(df, fwver_tr, on=['user_id'], how='left')\n",
    "        df = pd.merge(df, pro_tr_fwver_cnt, on=['user_id'], how='left')\n",
    "    else:\n",
    "        df = pd.merge(df, time_te, on=['user_id'], how='left')\n",
    "        df = pd.merge(df, fwver_te, on=['user_id'], how='left')\n",
    "        df = pd.merge(df, pro_te_fwver_cnt, on=['user_id'], how='left')\n",
    "    print('done.')\n",
    "    \n",
    "    # df에 column 추가 :주말여부별, 주별, 일별, 시간별 에러타입 변수\n",
    "    if train == True:\n",
    "        m_wok,std_wok,m2_wok=we_or_wk(err,15000,10000)\n",
    "        m_wk,std_wk,m2_wk=wk(err,15000,10000)\n",
    "        m_dy,std_dy,m2_dy=dy(err,15000,10000)\n",
    "        m_hr,std_hr,m2_hr=hr(err,15000,10000)\n",
    "        df=pd.concat([df,m_wok,std_wok,m2_wok,m_wk,std_wk,m2_wk,m_dy,std_dy,m2_dy,m_hr,std_hr,m2_hr],axis=1)\n",
    "    else:\n",
    "        m_wok,std_wok,m2_wok=we_or_wk(err,14999,30000)\n",
    "        m_wk,std_wk,m2_wk=wk(err,14999,30000)\n",
    "        m_dy,std_dy,m2_dy=dy(err,14999,30000)\n",
    "        m_hr,std_hr,m2_hr=hr(err,14999,30000)\n",
    "        df=pd.concat([df,m_wok,std_wok,m2_wok,m_wk,std_wk,m2_wk,m_dy,std_dy,m2_dy,m_hr,std_hr,m2_hr],axis=1)\n",
    "    \n",
    "    print('done.')\n",
    "    \n",
    "    df.fillna(0, inplace=True) # quality log 가 없는 유저들은 nan -> 0으로 처리해줘야함.\n",
    "    \n",
    "    if train == True: # train data인 경우에는 라벨링 값이 필요\n",
    "        angry_users = train_problem['user_id'].unique()\n",
    "        df['angry'] = [1 if user in angry_users else 0 for user in df['user_id']] # label data : 불만사용자면 1, 아니면 0 으로 라벨링\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = make_dataframe(train_err, train_qual, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = make_dataframe(test_err, test_qual, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import lightgbm\n",
    "from lightgbm import LGBMClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "# from bayes_opt import BayesianOptimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd                         # 데이터 분석 라이브러리\n",
    "import numpy as np                          # 계산 라이브러리\n",
    "from tqdm import tqdm                       # 진행바\n",
    "from sklearn.metrics import roc_auc_score   # AUC 스코어 계산\n",
    "from sklearn.model_selection import KFold,StratifiedKFold   # K-fold CV    \n",
    "from bayes_opt import BayesianOptimization  # 베이지안 최적화 라이브러리  \n",
    "from functools import partial               # 함수 변수 고정\n",
    "import lightgbm as lgb                      # LightGBM 라이브러리\n",
    "import warnings                             \n",
    "warnings.filterwarnings(\"ignore\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x=train_df.iloc[:,1:-1]\n",
    "test_x=test_df.iloc[:,1:]\n",
    "y = train_df.iloc[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lgb_cv(num_leaves, learning_rate, n_estimators, subsample, colsample_bytree, reg_alpha, reg_lambda, x_data=None, y_data=None, n_splits=5, output='score'):\n",
    "    score = 0\n",
    "    kf = StratifiedKFold(n_splits=n_splits,random_state=2021,shuffle = True)\n",
    "    models = []\n",
    "    for train_index, valid_index in kf.split(x_data,y_data):\n",
    "        x_train, y_train = x_data.iloc[train_index], y_data[train_index]\n",
    "        x_valid, y_valid = x_data.iloc[valid_index], y_data[valid_index]\n",
    "        \n",
    "        model = lgb.LGBMClassifier(\n",
    "            num_leaves = int(num_leaves), \n",
    "            learning_rate = learning_rate, \n",
    "            n_estimators = int(n_estimators), \n",
    "            subsample = np.clip(subsample, 0, 1), \n",
    "            colsample_bytree = np.clip(colsample_bytree, 0, 1), \n",
    "            reg_alpha = reg_alpha, \n",
    "            reg_lambda = reg_lambda\n",
    "        )\n",
    "        \n",
    "        model.fit(x_train, y_train,eval_set=[(x_valid,y_valid)],early_stopping_rounds=300,eval_metric=['auc'],verbose=0)\n",
    "        best_iter = model.best_iteration_\n",
    "#         print(best_iter)\n",
    "        models.append(model)\n",
    "        \n",
    "        pred = model.predict_proba(x_valid,num_iteration=best_iter)[:, 1]\n",
    "        true = y_valid\n",
    "        \n",
    "        score += roc_auc_score(true, pred)/n_splits\n",
    "    \n",
    "    if output == 'score':\n",
    "        return score\n",
    "    if output == 'model':\n",
    "        return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  모델과 관련없는 변수 고정\n",
    "func_fixed = partial(lgb_cv, x_data=train_x, y_data=y, n_splits=5, output='score') \n",
    "# 베이지안 최적화 범위 설정\n",
    "lgbBO = BayesianOptimization(\n",
    "    func_fixed, \n",
    "    {\n",
    "        'num_leaves': (1, 500),        # num_leaves,       범위(16~1024)\n",
    "        'learning_rate': (0.0001, 0.1),  # learning_rate,    범위(0.0001~0.1)\n",
    "        'n_estimators': (1, 2000),      # n_estimators,     범위(16~1024)\n",
    "        'subsample': (0, 1),             # subsample,        범위(0~1)\n",
    "        'colsample_bytree': (0, 1),      # colsample_bytree, 범위(0~1)\n",
    "        'reg_alpha': (0, 10),            # reg_alpha,        범위(0~10)\n",
    "        'reg_lambda': (0, 50),           # reg_lambda,       범위(0~50)\n",
    "    }, \n",
    "    random_state=4321                    # 시드 고정\n",
    ")\n",
    "lgbBO.maximize(init_points=15, n_iter=20) # 처음 5회 랜덤 값으로 score 계산 후 30회 최적화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  모델과 관련없는 변수 고정\n",
    "func_fixed = partial(lgb_cv, x_data=train_x, y_data=y, n_splits=5, output='score') \n",
    "# 베이지안 최적화 범위 설정\n",
    "lgbBO = BayesianOptimization(\n",
    "    func_fixed, \n",
    "    {\n",
    "        'num_leaves': (1, 500),        # num_leaves,       범위(16~1024)\n",
    "        'learning_rate': (0.0001, 0.1),  # learning_rate,    범위(0.0001~0.1)\n",
    "        'n_estimators': (1, 2000),      # n_estimators,     범위(16~1024)\n",
    "        'subsample': (0.1, 1),             # subsample,        범위(0~1)\n",
    "        'colsample_bytree': (0.1, 1),      # colsample_bytree, 범위(0~1)\n",
    "        'reg_alpha': (0, 10),            # reg_alpha,        범위(0~10)\n",
    "        'reg_lambda': (0, 50),           # reg_lambda,       범위(0~50)\n",
    "    }, \n",
    "    random_state=4321                    # 시드 고정\n",
    ")\n",
    "lgbBO.maximize(init_points=15, n_iter=20) # 처음 5회 랜덤 값으로 score 계산 후 30회 최적화\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = lgbBO.max['params']\n",
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = lgbBO.max['params']\n",
    "models = lgb_cv(\n",
    "    params['num_leaves'], \n",
    "    params['learning_rate'], \n",
    "    params['n_estimators'], \n",
    "    params['subsample'], \n",
    "    params['colsample_bytree'], \n",
    "    params['reg_alpha'], \n",
    "    params['reg_lambda'], \n",
    "    x_data=train_x, y_data=y, n_splits=10, output='model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = lgbBO.max['params']\n",
    "score = lgb_cv(\n",
    "    params['num_leaves'], \n",
    "    params['learning_rate'], \n",
    "    params['n_estimators'], \n",
    "    params['subsample'], \n",
    "    params['colsample_bytree'], \n",
    "    params['reg_alpha'], \n",
    "    params['reg_lambda'], \n",
    "    x_data=train_x, y_data=y, n_splits=5, output='score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 score\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = []\n",
    "for model in models:\n",
    "    pred = model.predict_proba(test_x)[:, 1]\n",
    "    preds.append(pred)\n",
    "pred = np.mean(preds, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_submission['problem'] = pred\n",
    "test_submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=train_df['angry'].values\n",
    "train_x=train_df.drop(['user_id','angry'],axis=1)\n",
    "test_x=test_df.drop(['user_id'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def catboost_modeling(x_train, y_train, x_test, grow_policy, depth, learning_rate, l2_leaf_reg, random_seed,n_split):\n",
    "    cat_model=[]\n",
    "    aucs=[]\n",
    "\n",
    "    test_pred = pd.Series([0 for x in range(len(x_test))], index=x_test.index)\n",
    "\n",
    "\n",
    "    kf = StratifiedKFold(n_splits=n_split,random_state=2021,shuffle = True)\n",
    "    for train_index, valid_index in kf.split(x_train,y_train):\n",
    "        train_X, train_y = x_train.iloc[train_index], y_train[train_index]\n",
    "        valid_X, valid_y = x_train.iloc[valid_index], y_train[valid_index]\n",
    "\n",
    "\n",
    "        model = CatBoostClassifier(eval_metric = 'AUC',             \n",
    "                                 iterations = 2000,               \n",
    "                                 metric_period = 100,          \n",
    "                                 early_stopping_rounds = 300,     \n",
    "                                 task_type = 'CPU',                \n",
    "                                 grow_policy = grow_policy,      \n",
    "                                 depth = depth,                  \n",
    "                                 learning_rate = learning_rate,  \n",
    "                                 l2_leaf_reg = l2_leaf_reg,        \n",
    "                                 random_seed = random_seed     \n",
    "                                 \n",
    "                                 )\n",
    "\n",
    "        model.fit(train_X, train_y, eval_set=(valid_X, valid_y))\n",
    "        aucs.append(model.best_score_['validation']['AUC'])\n",
    "        cat_model.append(model)\n",
    "        \n",
    "    \n",
    "        test_pred += model.predict_proba(x_test)[:,1] / (n_split)\n",
    "\n",
    "\n",
    "    return test_pred,cat_model,aucs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_result,models,aucs=catboost_modeling(train_x, y, test_x, 'Depthwise', 10, 0.03, 30, 2021,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# k-fold 결과 평균 AUC\n",
    "sum(aucs)/10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test data를 k-fold 모델들로 예측한 값의 평균\n",
    "preds = []\n",
    "for model in models:\n",
    "    pred = model.predict_proba(test_x)[:, 1]\n",
    "    preds.append(pred)\n",
    "pred = np.mean(preds, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 제출 결과물 저장\n",
    "sample_submission = pd.read_csv('sample_submission.csv')\n",
    "sample_submission['problem']=pred\n",
    "sample_submission.to_csv('CatBoost_result.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
